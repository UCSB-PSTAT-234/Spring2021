{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stone-livestock",
   "metadata": {},
   "source": [
    "# Mid-quarter Check-in"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aboriginal-technology",
   "metadata": {},
   "source": [
    "## Midterm\n",
    "\n",
    "* Monday, May 10 between 10 am and 10 pm\n",
    "* Once started, time limited at 1 hour\n",
    "* One attempt (not like weekly quizzes)\n",
    "* Covers up to material up to today (May 6)\n",
    "* Through GauchoSpaceFormat like quizzes\n",
    "* More in-depth questions and free responses\n",
    "* Question that uses Jupyter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "careful-bench",
   "metadata": {},
   "source": [
    "## Group Project\n",
    "\n",
    "* Required to be place in a team by Monday 10 (before end of the day)\n",
    "* Fill-out [Google sheet](https://docs.google.com/spreadsheets/d/1P1mt9IPMGzM6iMCh2Q7XIO3x_pg7GspzFE36gMv6-mE/edit?usp=sharing)\n",
    "* I will randomly assign those without teams on May 11\n",
    "* Project deliverable will be a project write-up, Github repository with code and possibly data (if the data is public), and a recorded video presentation\n",
    "* Deadline is June 11"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "false-bumper",
   "metadata": {},
   "source": [
    "## Improving Recommender System\n",
    "\n",
    "How can we improve the recommender system we developed? One of the ways is to first note the reconstructed ratings can be smaller than 1 and greater than 5. This is unintuitive outside of the movie ratings scale. Let's improve our approach by confining our ratings to [1, 5]. \n",
    "\n",
    "First note that we can write a more general form of the objective as follows. \n",
    "$$ \\min_{U,V} \\| R - h(VU^T) \\|_F^2 = \\sum_{m,i} (r_{mi} - h(v_m u_i^T))^2, $$\n",
    "where $h$ is some element-wise function of $VU^T$.\n",
    "\n",
    "The gradient can be expressed in terms of the chain rule involving $h$: \n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\frac{\\partial}{\\partial u_i} h_{mi}(v_m u_i^T) &= -2(r_{mi} - h_{mi}(v_m u_i^T))\\cdot \\frac{\\partial}{\\partial u_i}h_{mi}(v_m u_i^T)\\\\\n",
    "\\frac{\\partial}{\\partial v_m} h_{mi}(v_m u_i^T) &= -2(r_{mi} - h_{mi}(v_m u_i^T))\\cdot \\frac{\\partial}{\\partial v_m}h_{mi}(v_m u_i^T).\n",
    "\\end{aligned}\n",
    "$$\n",
    "You have seen the simplest case when $h_{mi}(v_m u_i^T) =v_m u_i^T$ (verify the gradient).\n",
    "\n",
    "Now, to confine ratings to between the allowed range, we can use the logistic function as function $h$. Logistic function is defined as \n",
    "$$ h(x) = \\frac{1}{1+e^{-x}}. $$\n",
    "It is straightforward to show the derivative is \n",
    "$$ h'(x) = \\frac{e^{-x}}{(1+e^{-x})^2} = h(x)(1-h(x)). $$\n",
    "According to the new objective function, rewrite update functions analytically.\n",
    "\n",
    "Similar to logistic regression that maps the real line to the open interval (0, 1),\n",
    "we can rescale the input ratings from $r_{mi}\\in [1, 5]$ to $r_{mi}\\in [0, 1]$. Then calculate the new $\\hat r_{mi}\\in [0, 1]$ back to $r_{mi}\\in [1, 5]$."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
